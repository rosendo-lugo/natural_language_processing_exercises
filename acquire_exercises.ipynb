{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d309f1-8af7-44ed-b1b5-393bef81288b",
   "metadata": {},
   "source": [
    "# Acquire Data through Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243dfd8e-b9f7-4e87-8868-a2a026965170",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "By the end of this exercise, you should have a file named acquire.py that contains the specified functions. If you wish, you may break your work into separate files for each website (e.g. acquire_codeup_blog.py and acquire_news_articles.py), but the end function should be present in acquire.py (that is, acquire.py should import get_blog_articles from the acquire_codeup_blog module.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f546dd54-0707-4a00-acbc-b5d4e1823754",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf83be82-9271-4976-b356-d9023c0021d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# webpage scraping imports\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd1c2b6-f825-4464-8ca0-aaab729d4305",
   "metadata": {},
   "source": [
    "## 1. Codeup Blog Articles\n",
    "\n",
    "Visit https://codeup.com/blog/Codeup's Blog and record the urls for at least 5 distinct blog posts. For each post, you should scrape at least the post's title and content.\n",
    "\n",
    "Encapsulate your work in a function named get_blog_articles that will return a list of dictionaries, with each dictionary representing one article. The shape of each dictionary should look like this:\n",
    "\n",
    "\n",
    "    {\n",
    "        'title': 'the title of the article',\n",
    "        'content': 'the full text content of the article'\n",
    "    }\n",
    "Plus any additional properties you think might be helpful.\n",
    "\n",
    "Bonus: Scrape the text of all the articles linked on codeup's blog page.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a14573-fe8a-4d76-83da-19aab3967019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e9077b7-7bfc-401a-888b-16a8db045387",
   "metadata": {},
   "source": [
    "## News Articles\n",
    "\n",
    "We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics.\n",
    "\n",
    "Write a function that scrapes the news articles for the following topics:\n",
    "\n",
    "    •Business\n",
    "    •Sports\n",
    "    •Technology\n",
    "    •Entertainment\n",
    "The end product of this should be a function named get_news_articles that returns a list of dictionaries, where each dictionary has this shape:\n",
    "\n",
    "\n",
    "    {\n",
    "        'title': 'The article title',\n",
    "        'content': 'The article content',\n",
    "        'category': 'business' # for example\n",
    "    }\n",
    "Hints:\n",
    "\n",
    "a. Start by inspecting the website in your browser. Figure out which elements will be useful.    \n",
    "b. Start by creating a function that handles a single article and produces a dictionary like the one above.    \n",
    "c. Next create a function that will find all the articles on a single page and call the function you created in the last step for every article on the page.    \n",
    "d. Now create a function that will use the previous two functions to scrape the articles from all the pages that you need, and do any additional processing that needs to be done.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dcd96f-1ad9-43e6-b1f4-ac2cc7a14b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4d385f-0027-4d3a-a469-f3007e7579de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4991b63-38e8-421d-9e1a-e3db4ed34af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dd67add-ffd0-4739-a186-a832ab609e14",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd69ac2-43b4-4daf-bc46-7922cdaa0792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
